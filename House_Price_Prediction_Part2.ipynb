{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House price prediction using multiple regression analysis\n",
    "\n",
    "# Part 2: Regression Models\n",
    "\n",
    "The following notebook presents a thought process of predicting a continuous variable through Machine Learning methods. More specifically, we want to predict house prices based on multiple features using regression analysis. \n",
    "\n",
    "As an example, we will use a dataset of house sales in King County, where Seattle is located.\n",
    "\n",
    "In this second notebook we will apply multiple regression models. We will talk about model complexity and how one can select the best predictive model using a validation set or cross-validation techniques.\n",
    "\n",
    "## 1. Preparation\n",
    "\n",
    "As in Part 1, Let's first load the libraries and the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # NumPy is the fundamental package for scientific computing\n",
    "\n",
    "import pandas as pd # Pandas is an easy-to-use data structures and data analysis tools\n",
    "pd.set_option('display.max_columns', None) # To display all columns\n",
    "\n",
    "import matplotlib.pyplot as plt # Matplotlib is a python 2D plotting library\n",
    "%matplotlib inline \n",
    "# A magic command that tells matplotlib to render figures as static images in the Notebook.\n",
    "\n",
    "import seaborn as sns # Seaborn is a visualization library based on matplotlib (attractive statistical graphics).\n",
    "sns.set_style('whitegrid') # One of the five seaborn themes\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # To ignore some of seaborn warning msg\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn import linear_model # Scikit learn library that implements generalized linear models\n",
    "from sklearn import neighbors # provides functionality for unsupervised and supervised neighbors-based learning methods\n",
    "from sklearn.metrics import mean_squared_error # Mean squared error regression loss\n",
    "from sklearn import preprocessing # provides functions and classes to change raw feature vectors\n",
    "\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>2014-10-13</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>2014-12-09</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id       date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520 2014-10-13  221900.0         3       1.00         1180   \n",
       "1  6414100192 2014-12-09  538000.0         3       2.25         2570   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  condition  grade  sqft_above  \\\n",
       "0      5650     1.0           0     0          3      7        1180   \n",
       "1      7242     2.0           0     0          3      7        2170   \n",
       "\n",
       "   sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "0              0      1955             0    98178  47.5112 -122.257   \n",
       "1            400      1951          1991    98125  47.7210 -122.319   \n",
       "\n",
       "   sqft_living15  sqft_lot15  \n",
       "0           1340        5650  \n",
       "1           1690        7639  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"kc_house_data.csv\", parse_dates = ['date']) # load the data into a pandas dataframe\n",
    "data.head(2) # Show the first 2 lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "Let's reduce the dataset by dropping columns that won't be used during the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.drop(['id', 'date', 'zipcode'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation\n",
    "\n",
    "Following the correlation analysis in Part 1, let's create some new variables in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['basement_present'] = data['sqft_basement'].apply(lambda x: 1 if x > 0 else 0) # Indicate whether there is a basement or not\n",
    "data['renovated'] = data['yr_renovated'].apply(lambda x: 1 if x > 0 else 0) # 1 if the house has been renovated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode categorical variables using dummies\n",
    "\n",
    "A Dummy variable is an artificial variable created to represent an attribute with two or more distinct categories/levels. In this example, we will analyse *bedrooms* and *bathrooms* as continuous and therefore will only encode the following:\n",
    "\n",
    "* *floors*\n",
    "* *view*\n",
    "* *condition* and\n",
    "* *grade*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price               float64\n",
       "bedrooms              int64\n",
       "bathrooms           float64\n",
       "sqft_living           int64\n",
       "sqft_lot              int64\n",
       "waterfront            int64\n",
       "sqft_above            int64\n",
       "sqft_basement         int64\n",
       "yr_built              int64\n",
       "yr_renovated          int64\n",
       "lat                 float64\n",
       "long                float64\n",
       "sqft_living15         int64\n",
       "sqft_lot15            int64\n",
       "basement_present      int64\n",
       "renovated             int64\n",
       "floors#1.0          float64\n",
       "floors#1.5          float64\n",
       "floors#2.0          float64\n",
       "floors#2.5          float64\n",
       "floors#3.0          float64\n",
       "floors#3.5          float64\n",
       "view#0              float64\n",
       "view#1              float64\n",
       "view#2              float64\n",
       "view#3              float64\n",
       "view#4              float64\n",
       "condition#1         float64\n",
       "condition#2         float64\n",
       "condition#3         float64\n",
       "condition#4         float64\n",
       "condition#5         float64\n",
       "grade#1             float64\n",
       "grade#3             float64\n",
       "grade#4             float64\n",
       "grade#5             float64\n",
       "grade#6             float64\n",
       "grade#7             float64\n",
       "grade#8             float64\n",
       "grade#9             float64\n",
       "grade#10            float64\n",
       "grade#11            float64\n",
       "grade#12            float64\n",
       "grade#13            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorial_cols = ['floors', 'view', 'condition', 'grade']\n",
    "\n",
    "for cc in categorial_cols:\n",
    "    dummies = pd.get_dummies(data[cc], drop_first=False)\n",
    "    dummies = dummies.add_prefix(\"{}#\".format(cc))\n",
    "    data.drop(cc, axis=1, inplace=True)\n",
    "    data = data.join(dummies)\n",
    "    \n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data\n",
    "\n",
    "We will split the dataframe into training and testing data using a 80%/20% ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "train_data, test_data = train_test_split(data, train_size = 0.8, random_state = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Regression Models\n",
    "\n",
    "In this section, we will train numerous regression models on the train data (e.g., simple linear regression, lasso, nearest neighbor) and evaluate their performance using Root Mean Squared Error (RMSE) on the test data.\n",
    "\n",
    "### 2.1 Simple Linear Regression\n",
    "\n",
    "Let's first predict house prices using simple (one input) linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A function that take one input of the dataset and return the RMSE (of the test data), and the intercept and coefficient\n",
    "def simple_linear_model(train, test, input_feature):\n",
    "    regr = linear_model.LinearRegression() # Create a linear regression object\n",
    "    regr.fit(train.as_matrix(columns = [input_feature]), train.as_matrix(columns = ['price'])) # Train the model\n",
    "    RMSE = mean_squared_error(test.as_matrix(columns = ['price']), \n",
    "                              regr.predict(test.as_matrix(columns = [input_feature])))**0.5 # Calculate the RMSE on test data\n",
    "    return RMSE, regr.intercept_[0], regr.coef_[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's create a simple linear regression model using *sqft_living* as input and calculate the RMSE on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for sqft_living is: 268279.643883 \n",
      "intercept is: -36738.1773464\n",
      "coefficient is: 277.36412987\n"
     ]
    }
   ],
   "source": [
    "RMSE, w0, w1 = simple_linear_model(train_data, test_data, 'sqft_living')\n",
    "print 'RMSE for sqft_living is: %s ' %RMSE\n",
    "print 'intercept is: %s' %w0\n",
    "print 'coefficient is: %s' %w1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can run the same test on all the features in the dataset and assess which one would be the best estimator of house price using just a single linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>intercept</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sqft_living</td>\n",
       "      <td>268279.643883</td>\n",
       "      <td>277.364130</td>\n",
       "      <td>-3.673818e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sqft_above</td>\n",
       "      <td>304131.310592</td>\n",
       "      <td>266.306764</td>\n",
       "      <td>6.461714e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sqft_living15</td>\n",
       "      <td>320686.541323</td>\n",
       "      <td>314.359911</td>\n",
       "      <td>-8.502590e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bathrooms</td>\n",
       "      <td>324082.781919</td>\n",
       "      <td>246523.891877</td>\n",
       "      <td>1.863279e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>view#0</td>\n",
       "      <td>356019.001320</td>\n",
       "      <td>-435033.777431</td>\n",
       "      <td>9.322014e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sqft_basement</td>\n",
       "      <td>357843.745395</td>\n",
       "      <td>258.126523</td>\n",
       "      <td>4.642966e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>grade#11</td>\n",
       "      <td>357964.423743</td>\n",
       "      <td>965286.415396</td>\n",
       "      <td>5.222663e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>grade#10</td>\n",
       "      <td>360773.700418</td>\n",
       "      <td>556992.601325</td>\n",
       "      <td>5.107024e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bedrooms</td>\n",
       "      <td>361295.375626</td>\n",
       "      <td>117579.891853</td>\n",
       "      <td>1.436815e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lat</td>\n",
       "      <td>365041.433662</td>\n",
       "      <td>814499.981062</td>\n",
       "      <td>-3.819789e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          feature           RMSE      intercept   coefficient\n",
       "2     sqft_living  268279.643883     277.364130 -3.673818e+04\n",
       "5      sqft_above  304131.310592     266.306764  6.461714e+04\n",
       "11  sqft_living15  320686.541323     314.359911 -8.502590e+04\n",
       "1       bathrooms  324082.781919  246523.891877  1.863279e+04\n",
       "21         view#0  356019.001320 -435033.777431  9.322014e+05\n",
       "6   sqft_basement  357843.745395     258.126523  4.642966e+05\n",
       "40       grade#11  357964.423743  965286.415396  5.222663e+05\n",
       "39       grade#10  360773.700418  556992.601325  5.107024e+05\n",
       "0        bedrooms  361295.375626  117579.891853  1.436815e+05\n",
       "9             lat  365041.433662  814499.981062 -3.819789e+07"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_list = data.columns.values.tolist() # list of column name\n",
    "input_list.remove('price')\n",
    "simple_linear_result = pd.DataFrame(columns = ['feature', 'RMSE', 'intercept', 'coefficient'])\n",
    "\n",
    "# loop that calculate the RMSE of the test data for each input \n",
    "for p in input_list:\n",
    "    RMSE, w1, w0 = simple_linear_model(train_data, test_data, p)\n",
    "    simple_linear_result = simple_linear_result.append({'feature':p, 'RMSE':RMSE, 'intercept':w0, 'coefficient': w1}\n",
    "                                                       ,ignore_index=True)\n",
    "simple_linear_result.sort_values('RMSE').head(10) # display the 10 best estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using simple linear regression, *sqft_living* provides the smallest test error estimate of house price for the dataset considered. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Multiple Regression\n",
    "\n",
    "Now let's try to predict *price* using multiple features. We can modify the simple linear regression function above to take multiple features as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A function that take multiple features as input and return the RMSE (of the test data), and the  intercept and coefficients\n",
    "def multiple_regression_model(train, test, input_features):\n",
    "    regr = linear_model.LinearRegression() # Create a linear regression object\n",
    "    regr.fit(train.as_matrix(columns = input_features), train.as_matrix(columns = ['price'])) # Train the model\n",
    "    RMSE = mean_squared_error(test.as_matrix(columns = ['price']), \n",
    "                              regr.predict(test.as_matrix(columns = input_features)))**0.5 # Calculate the RMSE on test data\n",
    "    return RMSE, regr.intercept_[0], regr.coef_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with a few examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 264872.283555, intercept: 81100.9596775, coefficients: [[   306.15090562   7913.53847651 -57658.90103459]]\n",
      "RMSE: 282802.364962, intercept: 303531.292188, coefficients: [[  1.98928518e+02  -3.17760670e+05   7.92684094e+04]]\n",
      "RMSE: 323412.269276, intercept: -18432.9057072, coefficients: [[ 235300.89998266   18030.65120532]]\n",
      "RMSE: 320893.658432, intercept: 507958.889992, coefficients: [[ -3.31957675e+05   1.35299763e+06   8.56179339e+04   1.24073575e+02]]\n",
      "RMSE: 260210.048524, intercept: 205076.198921, coefficients: [[    258.00653033    -244.89749378 -223120.61245789]]\n"
     ]
    }
   ],
   "source": [
    "print 'RMSE: %s, intercept: %s, coefficients: %s' %multiple_regression_model(train_data, \n",
    "                                                                             test_data, ['sqft_living','bathrooms','bedrooms'])\n",
    "print 'RMSE: %s, intercept: %s, coefficients: %s' %multiple_regression_model(train_data, \n",
    "                                                                             test_data, ['sqft_above','view#0','bathrooms'])\n",
    "print 'RMSE: %s, intercept: %s, coefficients: %s' %multiple_regression_model(train_data, \n",
    "                                                                             test_data, ['bathrooms','bedrooms'])\n",
    "print 'RMSE: %s, intercept: %s, coefficients: %s' %multiple_regression_model(train_data, \n",
    "                                                                             test_data, ['view#0','grade#12','bedrooms','sqft_basement'])\n",
    "print 'RMSE: %s, intercept: %s, coefficients: %s' %multiple_regression_model(train_data, \n",
    "                                                                             test_data, ['sqft_living','bathrooms','view#0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also try to fit a higher-order polynomial on the input. For example, we can try to fit a qudratic function on *sqft_living*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 246063.959207, intercept: 172106.560106, coefficients: [[  9.31721994e+01   3.37454932e-02]]\n"
     ]
    }
   ],
   "source": [
    "train_data['sqft_living_squared'] = train_data['sqft_living'].apply(lambda x: x**2) # create a new column in train_data\n",
    "test_data['sqft_living_squared'] = test_data['sqft_living'].apply(lambda x: x**2) # create a new column in test_data\n",
    "print 'RMSE: %s, intercept: %s, coefficients: %s' %multiple_regression_model(train_data, \n",
    "                                                                             test_data, ['sqft_living','sqft_living_squared'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we can get better performance than simple linear models, a few problems remain. \n",
    "\n",
    "* First, we don't know which feature to select. Obviously some combinations of features will yield smaller RMSE on the test set.\n",
    "* Second, we don't know how many features to select. This is because the more features we incorporate in the train model, the more overfit we get on the train data, resulting in higher error on the test data.\n",
    "\n",
    "One solution would be to test multiple features combinations (all?) and keep the solution with the smallest error value calculated on the test data. However, this is an overly optimistic approach, since the model complexity is selected to minimize the test error (error is biased). A more sophisticated approach is to use two sets for testing our models, a.k.a: a validation set and a test set. We select model complexity to minimize error on the validation set and approximate the generalization error based on the test set.\n",
    "\n",
    "Going through all subsets of features combinations is most often computationally infeasible. For example, having 30 features yield more than 1 billion combinations. Another approach is to use a greedy technique like a forward stepwise algorithm where the best estimator feature is added to the set of already selected features at each iteration. For example, let's pretend that the best single estimator is *sqft_living*. In the 2nd step of the greedy algorithm, we test all the remaining features one by one in combinations with *sqft_living* (e.g., *sqft_living* and *bedrooms*, *sqft_living* and *waterfront*, etc) and select the best combination using training error. At the end, we select the model complexity (number of features) using the validation error and estimate the generalization error using the test set.\n",
    "\n",
    "Let's try this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17290, 49)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we're first going to add more features into the dataset.\n",
    "\n",
    "# sqft_living cubed\n",
    "train_data['sqft_living_cubed'] = train_data['sqft_living'].apply(lambda x: x**3) \n",
    "test_data['sqft_living_cubed'] = test_data['sqft_living'].apply(lambda x: x**3) \n",
    "\n",
    "# bedrooms_squared: this feature will mostly affect houses with many bedrooms.\n",
    "train_data['bedrooms_squared'] = train_data['bedrooms'].apply(lambda x: x**2) \n",
    "test_data['bedrooms_squared'] = test_data['bedrooms'].apply(lambda x: x**2)\n",
    "\n",
    "# bedrooms times bathrooms gives what's called an \"interaction\" feature. It is large when both of them are large.\n",
    "train_data['bed_bath_rooms'] = train_data['bedrooms']*train_data['bathrooms']\n",
    "test_data['bed_bath_rooms'] = test_data['bedrooms']*test_data['bathrooms']\n",
    "\n",
    "# Taking the log of squarefeet has the effect of bringing large values closer together and spreading out small values.\n",
    "train_data['log_sqft_living'] = train_data['sqft_living'].apply(lambda x: log(x))\n",
    "test_data['log_sqft_living'] = test_data['sqft_living'].apply(lambda x: log(x))\n",
    "\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the train_data to include a validation set (train_data2 = 60%, validation_data = 20%, test_data = 20%)\n",
    "train_data_2, validation_data = train_test_split(train_data, train_size = 0.75, random_state = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A function that take multiple features as input and return the RMSE (of the train and validation data)\n",
    "def RMSE(train, validation, features, new_input):\n",
    "    features_list = list(features)\n",
    "    features_list.append(new_input)\n",
    "    regr = linear_model.LinearRegression() # Create a linear regression object\n",
    "    regr.fit(train.as_matrix(columns = features_list), train.as_matrix(columns = ['price'])) # Train the model\n",
    "    RMSE_train = mean_squared_error(train.as_matrix(columns = ['price']), \n",
    "                              regr.predict(train.as_matrix(columns = features_list)))**0.5 # Calculate the RMSE on train data\n",
    "    RMSE_validation = mean_squared_error(validation.as_matrix(columns = ['price']), \n",
    "                              regr.predict(validation.as_matrix(columns = features_list)))**0.5 # Calculate the RMSE on train data\n",
    "    return RMSE_train, RMSE_validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>train_error</th>\n",
       "      <th>validation_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sqft_living_squared</td>\n",
       "      <td>249721.440480</td>\n",
       "      <td>268747.213950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lat</td>\n",
       "      <td>229419.062478</td>\n",
       "      <td>252069.707424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>waterfront</td>\n",
       "      <td>219240.069871</td>\n",
       "      <td>241979.268406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>view#0</td>\n",
       "      <td>214598.840402</td>\n",
       "      <td>235006.341864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sqft_living15</td>\n",
       "      <td>212061.440586</td>\n",
       "      <td>225553.945689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>yr_built</td>\n",
       "      <td>209106.952300</td>\n",
       "      <td>224631.813173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>grade#13</td>\n",
       "      <td>207150.588541</td>\n",
       "      <td>224190.105488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bathrooms</td>\n",
       "      <td>205130.520723</td>\n",
       "      <td>220147.077763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>grade#11</td>\n",
       "      <td>203469.225546</td>\n",
       "      <td>217463.284605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>grade#10</td>\n",
       "      <td>201188.054657</td>\n",
       "      <td>212822.430513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>grade#12</td>\n",
       "      <td>198206.357564</td>\n",
       "      <td>206889.961277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>grade#9</td>\n",
       "      <td>194396.120835</td>\n",
       "      <td>200131.271456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>grade#8</td>\n",
       "      <td>191829.045018</td>\n",
       "      <td>196721.407209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>grade#7</td>\n",
       "      <td>190795.419372</td>\n",
       "      <td>195123.929145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>view#4</td>\n",
       "      <td>189824.261708</td>\n",
       "      <td>195545.525439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>condition#5</td>\n",
       "      <td>189102.542859</td>\n",
       "      <td>194989.957808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sqft_living_cubed</td>\n",
       "      <td>188395.497956</td>\n",
       "      <td>215653.150504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>long</td>\n",
       "      <td>187947.022313</td>\n",
       "      <td>214924.040846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>condition#4</td>\n",
       "      <td>187536.098211</td>\n",
       "      <td>214809.627580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>yr_renovated</td>\n",
       "      <td>187080.601484</td>\n",
       "      <td>215263.306150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>renovated</td>\n",
       "      <td>186706.152536</td>\n",
       "      <td>214997.564561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>floors#1.0</td>\n",
       "      <td>186511.550441</td>\n",
       "      <td>215307.790744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>view#2</td>\n",
       "      <td>186357.363644</td>\n",
       "      <td>215418.323430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bed_bath_rooms</td>\n",
       "      <td>186217.158957</td>\n",
       "      <td>214035.613580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>floors#2.5</td>\n",
       "      <td>186102.702791</td>\n",
       "      <td>213924.003501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sqft_lot15</td>\n",
       "      <td>185989.051869</td>\n",
       "      <td>213464.047937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>basement_present</td>\n",
       "      <td>185883.921066</td>\n",
       "      <td>214876.863444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sqft_above</td>\n",
       "      <td>185805.566668</td>\n",
       "      <td>217453.155954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>floors#3.0</td>\n",
       "      <td>185776.782696</td>\n",
       "      <td>217405.452628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>grade#5</td>\n",
       "      <td>185750.456583</td>\n",
       "      <td>217371.361223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>floors#3.5</td>\n",
       "      <td>185730.554156</td>\n",
       "      <td>217386.548045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>sqft_basement</td>\n",
       "      <td>185716.964969</td>\n",
       "      <td>221367.775692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>bedrooms_squared</td>\n",
       "      <td>185704.784672</td>\n",
       "      <td>221217.748219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>sqft_lot</td>\n",
       "      <td>185693.726064</td>\n",
       "      <td>221197.624977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>grade#3</td>\n",
       "      <td>185682.676406</td>\n",
       "      <td>221305.890576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>bedrooms</td>\n",
       "      <td>185679.964784</td>\n",
       "      <td>221698.809200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>log_sqft_living</td>\n",
       "      <td>185677.991805</td>\n",
       "      <td>223483.928825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>condition#2</td>\n",
       "      <td>185676.072928</td>\n",
       "      <td>223525.134348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>grade#6</td>\n",
       "      <td>185674.912036</td>\n",
       "      <td>223827.924724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>view#1</td>\n",
       "      <td>185674.033300</td>\n",
       "      <td>223822.398963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>floors#1.5</td>\n",
       "      <td>185673.833295</td>\n",
       "      <td>223868.008481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>grade#4</td>\n",
       "      <td>185673.830091</td>\n",
       "      <td>223870.720189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>floors#2.0</td>\n",
       "      <td>185673.824393</td>\n",
       "      <td>223870.018899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>view#3</td>\n",
       "      <td>185673.823897</td>\n",
       "      <td>223867.208659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>sqft_living</td>\n",
       "      <td>185673.823688</td>\n",
       "      <td>223864.976253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>grade#1</td>\n",
       "      <td>185673.823768</td>\n",
       "      <td>223862.809278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>condition#1</td>\n",
       "      <td>185673.885285</td>\n",
       "      <td>223890.049936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>condition#3</td>\n",
       "      <td>185673.902031</td>\n",
       "      <td>223902.951194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                feature    train_error  validation_error\n",
       "0   sqft_living_squared  249721.440480     268747.213950\n",
       "1                   lat  229419.062478     252069.707424\n",
       "2            waterfront  219240.069871     241979.268406\n",
       "3                view#0  214598.840402     235006.341864\n",
       "4         sqft_living15  212061.440586     225553.945689\n",
       "5              yr_built  209106.952300     224631.813173\n",
       "6              grade#13  207150.588541     224190.105488\n",
       "7             bathrooms  205130.520723     220147.077763\n",
       "8              grade#11  203469.225546     217463.284605\n",
       "9              grade#10  201188.054657     212822.430513\n",
       "10             grade#12  198206.357564     206889.961277\n",
       "11              grade#9  194396.120835     200131.271456\n",
       "12              grade#8  191829.045018     196721.407209\n",
       "13              grade#7  190795.419372     195123.929145\n",
       "14               view#4  189824.261708     195545.525439\n",
       "15          condition#5  189102.542859     194989.957808\n",
       "16    sqft_living_cubed  188395.497956     215653.150504\n",
       "17                 long  187947.022313     214924.040846\n",
       "18          condition#4  187536.098211     214809.627580\n",
       "19         yr_renovated  187080.601484     215263.306150\n",
       "20            renovated  186706.152536     214997.564561\n",
       "21           floors#1.0  186511.550441     215307.790744\n",
       "22               view#2  186357.363644     215418.323430\n",
       "23       bed_bath_rooms  186217.158957     214035.613580\n",
       "24           floors#2.5  186102.702791     213924.003501\n",
       "25           sqft_lot15  185989.051869     213464.047937\n",
       "26     basement_present  185883.921066     214876.863444\n",
       "27           sqft_above  185805.566668     217453.155954\n",
       "28           floors#3.0  185776.782696     217405.452628\n",
       "29              grade#5  185750.456583     217371.361223\n",
       "30           floors#3.5  185730.554156     217386.548045\n",
       "31        sqft_basement  185716.964969     221367.775692\n",
       "32     bedrooms_squared  185704.784672     221217.748219\n",
       "33             sqft_lot  185693.726064     221197.624977\n",
       "34              grade#3  185682.676406     221305.890576\n",
       "35             bedrooms  185679.964784     221698.809200\n",
       "36      log_sqft_living  185677.991805     223483.928825\n",
       "37          condition#2  185676.072928     223525.134348\n",
       "38              grade#6  185674.912036     223827.924724\n",
       "39               view#1  185674.033300     223822.398963\n",
       "40           floors#1.5  185673.833295     223868.008481\n",
       "41              grade#4  185673.830091     223870.720189\n",
       "42           floors#2.0  185673.824393     223870.018899\n",
       "43               view#3  185673.823897     223867.208659\n",
       "44          sqft_living  185673.823688     223864.976253\n",
       "45              grade#1  185673.823768     223862.809278\n",
       "46          condition#1  185673.885285     223890.049936\n",
       "47          condition#3  185673.902031     223902.951194"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_list = train_data_2.columns.values.tolist() # list of column name\n",
    "input_list.remove('price')\n",
    "\n",
    "# list of features included in the regression model and the calculated train and validation errors (RMSE)\n",
    "regression_greedy_algorithm = pd.DataFrame(columns = ['feature', 'train_error', 'validation_error'])  \n",
    "i = 0\n",
    "temp_list = []\n",
    "\n",
    "# a while loop going through all the features in the dataframe\n",
    "while i < len(train_data_2.columns)-1:\n",
    "    \n",
    "    # a temporary dataframe to select the best feature at each iteration\n",
    "    temp = pd.DataFrame(columns = ['feature', 'train_error', 'validation_error'])\n",
    "    \n",
    "    # a for loop to test all the remaining features\n",
    "    for p in input_list:\n",
    "        RMSE_train, RMSE_validation = RMSE(train_data_2, validation_data, temp_list, p)\n",
    "        temp = temp.append({'feature':p, 'train_error':RMSE_train, 'validation_error':RMSE_validation}, ignore_index=True)\n",
    "        \n",
    "    temp = temp.sort_values('train_error') # select the best feature using train error\n",
    "    best = temp.iloc[0,0]\n",
    "    temp_list.append(best)\n",
    "    regression_greedy_algorithm = regression_greedy_algorithm.append({'feature': best, \n",
    "                                                  'train_error': temp.iloc[0,1], 'validation_error': temp.iloc[0,2]}, \n",
    "                                                 ignore_index=True) # add the feature to the dataframe\n",
    "    input_list.remove(best) # remove the best feature from the list of available features\n",
    "    i += 1\n",
    "regression_greedy_algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the validation error is minimum when we reach 16 features in the model (*condition#5\t*). We stop the selection here even if the training error keeps getting smaller (overfitting).\n",
    "\n",
    "Let's now calculate an estimation of the generalization error using *test_data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error (RMSE) is: 191328.013498\n"
     ]
    }
   ],
   "source": [
    "greedy_algo_features_list = regression_greedy_algorithm['feature'].tolist()[:15] # select the first 30 features\n",
    "test_error, _, _ = multiple_regression_model(train_data_2, test_data, greedy_algo_features_list)\n",
    "print 'test error (RMSE) is: %s' %test_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test error is getting smaller.\n",
    "\n",
    "* Note 1: We could have used k-fold cross validation instead of a validation set.\n",
    "* Note 2: Other greedy algorithms exist (e.g., backward stepwise, combining forward and backward steps)\n",
    "\n",
    "Now, instead of searching over a discrete set of solutions using greedy algorithms, we can use another technique called regularization. We start with all possible features in the model and shrink the coefficients (weights). Two main regularization techniques exist, Ridge regression (a.k.a L2 regularization) and Lasso regression (a.k.a L1 regularization).\n",
    "\n",
    "### 2.3 Ridge Regression\n",
    "\n",
    "Ridge regression aims to avoid overfitting by adding a cost to the Residual Sum of Squares (RSS) term of standard least squares that depends on the 2-norm of the coefficients.  The result is penalizing fits with large coefficients.  The strength of this penalty, and thus the fit vs. model complexity, is controlled by a parameter alpha (here called \"L2_penalty\").\n",
    "\n",
    "Let's test two models using alpha equal 1 and 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error (RMSE) is: 207440.450781\n",
      "test error (RMSE) is: 292909.565734\n"
     ]
    }
   ],
   "source": [
    "input_feature = train_data.columns.values.tolist() # list of column name\n",
    "input_feature.remove('price')\n",
    "\n",
    "for i in [1,10]:\n",
    "    ridge = linear_model.Ridge(alpha = i, normalize = True) # initialize the model\n",
    "    ridge.fit(train_data.as_matrix(columns = input_feature), train_data.as_matrix(columns = ['price'])) # fit the train data\n",
    "    print 'test error (RMSE) is: %s' %mean_squared_error(test_data.as_matrix(columns = ['price']), \n",
    "                              ridge.predict(test_data.as_matrix(columns = [input_feature])))**0.5 # predict price and test error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the question is, how do we pick alpha to minimize the error?\n",
    "\n",
    "Alpha is a measure of model complexity. So, as before, we could use a validation set to select alpha. However, that approach has a major disadvantage: it leaves fewer observations available for training. A better approach to overcome this issue is to use a cross-validation technique. It uses all of the training set in a smart way. k-fold cross-validation for example involves dividing the training set into k segments of roughly equal size. Similar to the validation set method, we measure the validation error with one of the segments designated as the validation set. The major difference is that we repeat the process k times. We then compute the average of the k validation errors, and use it as an estimate of the generalization error. We then select the alpha value that generate the smallest validation error. The best approximation occurs for validation sets of size 1, where k is equal to the number of observations. It is called leave-one-out cross validation. It is however computationally intensive.\n",
    "\n",
    "In this example we'll use a ridge regression with an implemented cross-validation method from the scikit learn library. By default, it performs Generalized Cross-Validation, which is a form of efficient Leave-One-Out cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha is: 0.090909091\n",
      "test error (RMSE) is: 191294.485755\n"
     ]
    }
   ],
   "source": [
    "ridgeCV = linear_model.RidgeCV(alphas = np.linspace(1.0e-10,1,num = 100), normalize = True, store_cv_values = True) # initialize the model\n",
    "ridgeCV.fit(train_data.as_matrix(columns = input_feature), train_data.as_matrix(columns = ['price'])) # fit the train data\n",
    "print 'best alpha is: %s' %ridgeCV.alpha_ # get the best alpha\n",
    "print 'test error (RMSE) is: %s' %mean_squared_error(test_data.as_matrix(columns = ['price']), \n",
    "                              ridgeCV.predict(test_data.as_matrix(columns = [input_feature])))**0.5 # predict price and test error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using every features in the dataset and a ridge regression model with an efficient  LOO cross-validation method yield a test error of 191294.\n",
    "\n",
    "### 2.4 Lasso Regression\n",
    "\n",
    "Lasso regression jointly shrinks coefficients to avoid overfitting, and implicitly performs feature selection by setting some coefficients exactly to 0 for sufficiently large penalty strength alpha (here called \"L1_penalty\"). In particular, lasso takes the RSS term of standard least squares and adds a 1-norm cost of the coefficients.\n",
    "\n",
    "Let 's train multiple models using different alpha values and asses the test error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method csr_matrix.getnnz of <1x48 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 47 stored elements in Compressed Sparse Row format>>\n",
      "test error (RMSE) is: 193326.649363\n",
      "<bound method csr_matrix.getnnz of <1x48 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 44 stored elements in Compressed Sparse Row format>>\n",
      "test error (RMSE) is: 193313.688132\n",
      "<bound method csr_matrix.getnnz of <1x48 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 39 stored elements in Compressed Sparse Row format>>\n",
      "test error (RMSE) is: 193229.877522\n",
      "<bound method csr_matrix.getnnz of <1x48 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 10 stored elements in Compressed Sparse Row format>>\n",
      "test error (RMSE) is: 217809.228424\n",
      "<bound method csr_matrix.getnnz of <1x48 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>>\n",
      "test error (RMSE) is: 243769.338181\n",
      "<bound method csr_matrix.getnnz of <1x48 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>>\n",
      "test error (RMSE) is: 289827.5898\n"
     ]
    }
   ],
   "source": [
    "for i in [0.01,0.1,1,250,500,1000]:\n",
    "    lasso = linear_model.Lasso(alpha = i, normalize = True) # initialize the model\n",
    "    lasso.fit(train_data.as_matrix(columns = input_feature), train_data.as_matrix(columns = ['price'])) # fit the train data\n",
    "    print lasso.sparse_coef_.getnnz # number of non zero weights\n",
    "    print 'test error (RMSE) is: %s' %mean_squared_error(test_data.as_matrix(columns = ['price']), \n",
    "                              lasso.predict(test_data.as_matrix(columns = [input_feature])))**0.5 # predict price and test error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As alpha increases, the number of features included in the model decrease. As in Ridge regression, we also can use cross-validation methods that select the best alpha to provide the best predictive accuracy. However, this technique tends to favor less sparse solutions and smaller alpha than optimal choice for feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha is: 36.9978057091\n",
      "number of non zero weigths is: 28\n",
      "test error (RMSE) is: 191627.546656\n"
     ]
    }
   ],
   "source": [
    "lassoCV = linear_model.LassoCV(normalize = True) # initialize the model (alphas are set automatically)\n",
    "lassoCV.fit(train_data.as_matrix(columns = input_feature), np.ravel(train_data.as_matrix(columns = ['price']))) # fit the train data\n",
    "print 'best alpha is: %s' %lassoCV.alpha_ # get the best alpha\n",
    "print 'number of non zero weigths is: %s' %np.count_nonzero(lassoCV.coef_) # number of non zero weights\n",
    "print 'test error (RMSE) is: %s' %mean_squared_error(test_data.as_matrix(columns = ['price']), \n",
    "                              lassoCV.predict(test_data.as_matrix(columns = [input_feature])))**0.5 # predict price and test error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "28 features remain in the model, yielding a test error of 191627.\n",
    "\n",
    "### 2.5 k-Nearest Neighbors (NN) Regression\n",
    "\n",
    "To finish, let's talk about another regression model, k-NN regression. The k-NN algorithm is used for estimating continuous variables. One such algorithm uses a weighted average of the k nearest neighbors, weighted by the inverse of their distance. It is the nonparamtric equivalent of ordinary least square regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error (RMSE) is: 195427.612114\n"
     ]
    }
   ],
   "source": [
    "# normalize the data\n",
    "train_X = train_data.as_matrix(columns = input_feature)\n",
    "scaler = preprocessing.StandardScaler().fit(train_X)\n",
    "train_X_scaled = scaler.transform(train_X)\n",
    "test_X = test_data.as_matrix(columns = [input_feature])\n",
    "test_X_scaled = scaler.transform(test_X)\n",
    "\n",
    "knn = neighbors.KNeighborsRegressor(n_neighbors=10, weights='distance') # initialize the model\n",
    "knn.fit(train_X_scaled, train_data.as_matrix(columns = ['price'])) # fit the train data\n",
    "print 'test error (RMSE) is: %s' %mean_squared_error(test_data.as_matrix(columns = ['price']), \n",
    "                              knn.predict(test_X_scaled))**0.5 # predict price and test error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the number of neighbor k is related to the complexity of the regression model. We can optimize the model accuracy by running cross-validation on the number of k-neighbors to include. \n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In this notebook I tried to give on overview of regression methods using a dataset of house sales. Obviously, many other methods exit for regression (e.g., Elastic Net, kernel regression, Bayesian regression). Model selection should be based on your data and application. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
